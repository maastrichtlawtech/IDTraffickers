{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6f49dc-b9c5-460a-a025-862990d3b0ed",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a009c4-4333-4694-8649-755dcb61d864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b68387-a9e5-4ba7-aeea-e33634c62752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = faiss.StandardGpuResources()  # use a single GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2304c387-5d03-4766-97b5-b33e013719e1",
   "metadata": {},
   "source": [
    "# Helper functions to generate recall@k, precision@k, and mean average precision@k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e60566e-7ee0-45b8-be4e-cad400c942b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, k):\n",
    "    recall_list = []\n",
    "    for index, values in enumerate(actual):\n",
    "        act_set = set(actual[index].tolist())\n",
    "        pred_set = set(predicted[index].tolist()[:k])\n",
    "        \"\"\"\n",
    "        if k < len(act_set):\n",
    "            result = round(len(act_set & pred_set) / k, 2)\n",
    "        else:\n",
    "            result = round(len(act_set & pred_set) / float(len(act_set)), 2)\n",
    "        \"\"\"\n",
    "        result = round(len(act_set & pred_set) / float(len(act_set)), 2)\n",
    "        recall_list.append(result)\n",
    "    return recall_list\n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=12):\n",
    "    \"\"\" Computes Precision at k for one sample\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    y_true: np.array\n",
    "            Array of correct recommendations (Order doesn't matter)\n",
    "    y_pred: np.array\n",
    "            Array of predicted recommendations (Order does matter)\n",
    "    k: int, optional\n",
    "       Maximum number of predicted recommendations\n",
    "            \n",
    "    Returns\n",
    "    _______\n",
    "    score: double\n",
    "           Precision at k\n",
    "    \"\"\"    \n",
    "    precision_list = []\n",
    "    for index, value in enumerate(y_true):\n",
    "        intersection = np.intersect1d(y_true[index], y_pred[index][:k])\n",
    "        precision_list.append(len(intersection) / k)\n",
    "    return precision_list\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cde718c-a4a8-4f9b-ae57-b34c8b52ea68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_results_for_untrained_models(model=\"style\", mode=\"most\"):\n",
    "    # declutr\n",
    "    train_embedding_filename = \"untrained_\" + model + \"data_train.pt\"\n",
    "    train_label_filename = \"untrained_\" + model + \"labels_train.pt\"\n",
    "\n",
    "    test_embedding_filename = \"untrained_\" + model + \"data_test.pt\"\n",
    "    test_label_filename = \"untrained_\" + model + \"labels_test.pt\"\n",
    "\n",
    "    train_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_embedding_filename), map_location=torch.device('cpu'))\n",
    "    train_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "\n",
    "    test_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_embedding_filename), map_location=torch.device('cpu'))\n",
    "    test_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "\n",
    "    all_embeddings = torch.cat([torch.tensor(train_embeddings), torch.tensor(test_embeddings)])\n",
    "    all_labels = torch.cat([torch.tensor(train_labels), torch.tensor(test_labels)])\n",
    "    \n",
    "    for percent in [1.0]:\n",
    "        print(\"*\"*50)\n",
    "        nr_vendors = int(torch.unique(all_labels).shape[0] * percent)\n",
    "        if mode == \"most\":\n",
    "            print(\"most active % vendors:\", percent * 100)\n",
    "            vendors = [vendor[0] for vendor in Counter(all_labels.tolist()).most_common()[:nr_vendors]]\n",
    "        else:\n",
    "            print(\"least active % vendors:\", percent * 100)\n",
    "            vendors = [vendor[0] for vendor in Counter(all_labels.tolist()).most_common()[-nr_vendors:]]\n",
    "            \n",
    "        vendorindex = [[i for i, x in enumerate(test_labels) if x == vendor] for vendor in vendors]\n",
    "        \n",
    "        vendor_embeddings, vendor_labels = ([] for i in range(2))\n",
    "        for index, vendor in enumerate(vendorindex):\n",
    "            for vendor_index in vendor:\n",
    "                vendor_embeddings.append(test_embeddings[vendor_index])\n",
    "                vendor_labels.append(vendors[index])\n",
    "        \n",
    "        vendor_embeddings = torch.tensor(vendor_embeddings)\n",
    "        vendor_labels = torch.tensor(vendor_labels)\n",
    "        \n",
    "        dim = train_embeddings.shape[1]\n",
    "        nb = train_embeddings.shape[0]\n",
    "        nq = train_embeddings.shape[0]\n",
    "\n",
    "        index = faiss.IndexFlatIP(dim)\n",
    "        # make it a flat GPU index\n",
    "        gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "        gpu_index_flat.add(train_embeddings) # add vectors to the index\n",
    "\n",
    "        k = 100\n",
    "        D, I = gpu_index_flat.search(vendor_embeddings, k)\n",
    "\n",
    "        true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "        for index, rank_indices in enumerate(I):\n",
    "            temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "            label = vendor_labels[index]\n",
    "            predicted_label_list.append(np.array(rank_indices))\n",
    "            true_label_list.append(np.where(train_labels == int(label))[0])\n",
    "\n",
    "        # print(\"-\"*50)\n",
    "        print(\"========== PRECISION@K ==========\")\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , np.mean(precision_at_k(true_label_list, predicted_label_list, k=i)), np.std(precision_at_k(true_label_list, predicted_label_list, k=i)))\n",
    "\n",
    "        print(\"========== RECALL@K ==========\")\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , np.mean(recall_at_k(true_label_list, predicted_label_list, k=i)), np.std(recall_at_k(true_label_list, predicted_label_list, k=i)))\n",
    "            \n",
    "        print(\"========== MAP@K ==========\")\n",
    "        true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "        for index, rank_indices in enumerate(I):\n",
    "            temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "            temp_actual_list.append(vendor_labels[index])\n",
    "            for rank in rank_indices:\n",
    "                temp_predicted_list.append(train_labels[rank])\n",
    "\n",
    "            predicted_label_list.append(temp_predicted_list)\n",
    "            true_label_list.append(temp_actual_list)\n",
    "\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , mapk(true_label_list, predicted_label_list, k=i), np.std([apk(a,p,k) for a,p in zip(actual, predicted)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c6b9df-245c-415d-b62e-1e7daf50127e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_results_for_trained_models(model=\"style\", mode=\"most\"):\n",
    "    # declutr\n",
    "    train_embedding_filename = \"trained_traindata_\" + model + \"_mean.pt\"\n",
    "    train_label_filename = \"trained_trainlabels_\" + model + \"_mean.pt\"\n",
    "\n",
    "    test_embedding_filename = \"trained_testdata_\" + model + \"_mean.pt\"\n",
    "    test_label_filename = \"trained_testlabels_\" + model + \"_mean.pt\"\n",
    "\n",
    "    train_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_embedding_filename), map_location=torch.device('cpu'))\n",
    "    train_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "\n",
    "    test_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_embedding_filename), map_location=torch.device('cpu'))\n",
    "    test_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "\n",
    "    all_embeddings = torch.cat([torch.tensor(train_embeddings), torch.tensor(test_embeddings)])\n",
    "    all_labels = torch.cat([torch.tensor(train_labels), torch.tensor(test_labels)])\n",
    "\n",
    "    \n",
    "    for percent in [1.0]:\n",
    "        print(\"*\"*50)\n",
    "        nr_vendors = int(torch.unique(all_labels).shape[0] * percent)\n",
    "        if mode == \"most\":\n",
    "            print(\"most active % vendors:\", percent * 100)\n",
    "            vendors = [vendor[0] for vendor in Counter(all_labels.tolist()).most_common()[:nr_vendors]]\n",
    "        else:\n",
    "            print(\"least active % vendors:\", percent * 100)\n",
    "            vendors = [vendor[0] for vendor in Counter(all_labels.tolist()).most_common()[-nr_vendors:]]\n",
    "            \n",
    "        vendorindex = [[i for i, x in enumerate(test_labels) if x == vendor] for vendor in vendors]\n",
    "        \n",
    "        vendor_embeddings, vendor_labels = ([] for i in range(2))\n",
    "        for index, vendor in enumerate(vendorindex):\n",
    "            for vendor_index in vendor:\n",
    "                vendor_embeddings.append(test_embeddings[vendor_index])\n",
    "                vendor_labels.append(vendors[index])\n",
    "        \n",
    "        vendor_embeddings = torch.stack(vendor_embeddings)\n",
    "        vendor_labels = torch.tensor(vendor_labels)\n",
    "        \n",
    "        dim = train_embeddings.shape[1]\n",
    "        nb = train_embeddings.shape[0]\n",
    "        nq = train_embeddings.shape[0]\n",
    "\n",
    "        index = faiss.IndexFlatIP(dim)\n",
    "        # make it a flat GPU index\n",
    "        gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "        gpu_index_flat.add(train_embeddings) # add vectors to the index\n",
    "\n",
    "        k = 100\n",
    "        D, I = gpu_index_flat.search(vendor_embeddings, k)\n",
    "\n",
    "        true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "        for index, rank_indices in enumerate(I):\n",
    "            temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "            label = vendor_labels[index]\n",
    "            predicted_label_list.append(np.array(rank_indices))\n",
    "            true_label_list.append(np.where(train_labels == int(label))[0])\n",
    "\n",
    "        # print(\"-\"*50)\n",
    "        print(\"========== PRECISION@K ==========\")\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , np.mean(precision_at_k(true_label_list, predicted_label_list, k=i)))\n",
    "\n",
    "        print(\"========== RECALL@K ==========\")\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , np.mean(recall_at_k(true_label_list, predicted_label_list, k=i)), np.std(recall_at_k(true_label_list, predicted_label_list, k=i)))\n",
    "            \n",
    "        print(\"========== MAP@K ==========\")\n",
    "        true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "        for index, rank_indices in enumerate(I):\n",
    "            temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "            temp_actual_list.append(vendor_labels[index])\n",
    "            for rank in rank_indices:\n",
    "                temp_predicted_list.append(train_labels[rank])\n",
    "\n",
    "            predicted_label_list.append(temp_predicted_list)\n",
    "            true_label_list.append(temp_actual_list)\n",
    "\n",
    "        # print(\"-\"*50)\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , mapk(true_label_list, predicted_label_list, k=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a87c626-716a-4cb0-84e8-69540d0cd95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_results_for_models(model=\"style\", mode=\"most\", model_type=\"trained\"):\n",
    "    \n",
    "    if model_type == \"trained\":\n",
    "        train_embedding_filename = \"trained_traindata_\" + model + \"_mean.pt\"\n",
    "        train_label_filename = \"trained_trainlabels_\" + model + \"_mean.pt\"\n",
    "\n",
    "        test_embedding_filename = \"trained_testdata_\" + model + \"_mean.pt\"\n",
    "        test_label_filename = \"trained_testlabels_\" + model + \"_mean.pt\"\n",
    "    else:\n",
    "        train_embedding_filename = \"untrained_\" + model + \"data_train.pt\"\n",
    "        train_label_filename = \"untrained_\" + model + \"labels_train.pt\"\n",
    "\n",
    "        test_embedding_filename = \"untrained_\" + model + \"data_test.pt\"\n",
    "        test_label_filename = \"untrained_\" + model + \"labels_test.pt\"\n",
    "\n",
    "    train_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_embedding_filename), map_location=torch.device('cpu'))\n",
    "    train_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "\n",
    "    test_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_embedding_filename), map_location=torch.device('cpu'))\n",
    "    test_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "\n",
    "    all_embeddings = torch.cat([torch.tensor(train_embeddings), torch.tensor(test_embeddings)])\n",
    "    all_labels = torch.cat([torch.tensor(train_labels), torch.tensor(test_labels)])\n",
    "    \n",
    "    for percent in [1.0]:\n",
    "        print(\"*\"*50)\n",
    "        nr_vendors = int(torch.unique(all_labels).shape[0] * percent)\n",
    "        if mode == \"most\":\n",
    "            print(\"most active % vendors:\", percent * 100)\n",
    "            vendors = [vendor[0] for vendor in Counter(all_labels.tolist()).most_common()[:nr_vendors]]\n",
    "        else:\n",
    "            print(\"least active % vendors:\", percent * 100)\n",
    "            vendors = [vendor[0] for vendor in Counter(all_labels.tolist()).most_common()[-nr_vendors:]]\n",
    "            \n",
    "        vendorindex = [[i for i, x in enumerate(test_labels) if x == vendor] for vendor in vendors]\n",
    "        \n",
    "        vendor_embeddings, vendor_labels = ([] for i in range(2))\n",
    "        for index, vendor in enumerate(vendorindex):\n",
    "            for vendor_index in vendor:\n",
    "                vendor_embeddings.append(test_embeddings[vendor_index])\n",
    "                vendor_labels.append(vendors[index])\n",
    "        \n",
    "        if model_type == \"trained\":\n",
    "            vendor_embeddings = torch.stack(vendor_embeddings)\n",
    "            vendor_labels = torch.tensor(vendor_labels)\n",
    "        else:\n",
    "            vendor_embeddings = torch.tensor(vendor_embeddings)\n",
    "            vendor_labels = torch.tensor(vendor_labels)\n",
    "        \n",
    "        dim = train_embeddings.shape[1]\n",
    "        nb = train_embeddings.shape[0]\n",
    "        nq = train_embeddings.shape[0]\n",
    "\n",
    "        index = faiss.IndexFlatIP(dim)\n",
    "        # make it a flat GPU index\n",
    "        gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "        gpu_index_flat.add(train_embeddings) # add vectors to the index\n",
    "\n",
    "        k = 100\n",
    "        D, I = gpu_index_flat.search(vendor_embeddings, k)\n",
    "\n",
    "        true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "        for index, rank_indices in enumerate(I):\n",
    "            temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "            label = vendor_labels[index]\n",
    "            predicted_label_list.append(np.array(rank_indices))\n",
    "            true_label_list.append(np.where(train_labels == int(label))[0])\n",
    "\n",
    "        # print(\"-\"*50)\n",
    "        print(\"========== PRECISION@K ==========\")\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , np.mean(precision_at_k(true_label_list, predicted_label_list, k=i)), np.std(precision_at_k(true_label_list, predicted_label_list, k=i)))\n",
    "\n",
    "        print(\"========== RECALL@K ==========\")\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , np.mean(recall_at_k(true_label_list, predicted_label_list, k=i)), np.std(recall_at_k(true_label_list, predicted_label_list, k=i)))\n",
    "            \n",
    "        print(\"========== MAP@K ==========\")\n",
    "        true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "        for index, rank_indices in enumerate(I):\n",
    "            temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "            temp_actual_list.append(vendor_labels[index])\n",
    "            for rank in rank_indices:\n",
    "                temp_predicted_list.append(train_labels[rank])\n",
    "\n",
    "            predicted_label_list.append(temp_predicted_list)\n",
    "            true_label_list.append(temp_actual_list)\n",
    "\n",
    "        for i in [1, 3, 5, 10, 20, 25, 50, 100]:\n",
    "            print(i , mapk(true_label_list, predicted_label_list, k=i), np.std([apk(a,p,i) for a,p in zip(true_label_list, predicted_label_list)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da9a04-1545-452b-bd6c-0d68c1fec217",
   "metadata": {},
   "source": [
    "# Trained and Un-trained DeCLUTr model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5741b-39c4-4a4c-a1e6-6dd651766a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_results_for_models(model=\"declutr\", mode=\"most\", model_type=\"untrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d58fb-f74c-4e3b-a190-0ed3c3473890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_results_for_models(model=\"declutr\", mode=\"most\", model_type=\"trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f533d9-6a2d-413f-8138-2ed330f511d3",
   "metadata": {},
   "source": [
    "# Trained and Un-trained Style Representation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa560b96-f0cb-4776-a694-0ba1d3e70506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_results_for_models(model=\"style\", mode=\"most\", model_type=\"untrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0d003-4dd0-4415-b72c-d982e422d4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_results_for_models(model=\"style\", mode=\"most\", model_type=\"trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4c063-1c56-4621-ba6d-2d0012c095a6",
   "metadata": {},
   "source": [
    "# R-Precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa43ea36-f653-490f-8883-85cf628996a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169c042a-d31e-4dd2-aec9-c4a6b94722dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_embedding_filename = \"trained_traindata_\" + \"declutr\" + \"_mean.pt\"\n",
    "train_label_filename = \"trained_trainlabels_\" + \"declutr\" + \"_mean.pt\"\n",
    "\n",
    "test_embedding_filename = \"trained_testdata_\" + \"declutr\" + \"_mean.pt\"\n",
    "test_label_filename = \"trained_testlabels_\" + \"declutr\" + \"_mean.pt\"\n",
    "\n",
    "\n",
    "train_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_embedding_filename), map_location=torch.device('cpu'))\n",
    "train_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "\n",
    "test_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_embedding_filename), map_location=torch.device('cpu'))\n",
    "test_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_label_filename), map_location=torch.device('cpu')).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0649065-c36d-4635-b8c7-c04a8861d9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = train_embeddings.shape[1]\n",
    "nb = train_embeddings.shape[0]\n",
    "nq = train_embeddings.shape[0]\n",
    "\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "# make it a flat GPU index\n",
    "gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "gpu_index_flat.add(train_embeddings) # add vectors to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52eac96a-68e7-47d2-8065-82df9b352aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ebd0feb-fa40-4950-bc71-5d215349e85c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4487/4487 [00:57<00:00, 78.16it/s] \n"
     ]
    }
   ],
   "source": [
    "vendor_dict = {}\n",
    "unique_vendors = torch.unique(torch.tensor(test_labels))\n",
    "\n",
    "pbar = tqdm(total=unique_vendors.shape[0])\n",
    "for vendor_id in unique_vendors:\n",
    "    vendor_id = int(vendor_id)\n",
    "    # train_dataset\n",
    "    train_adsidx = [i for i, x in enumerate(train_labels) if x == vendor_id]\n",
    "    vendor_dict[vendor_id] = len(train_adsidx)\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c4238a5-68a8-44aa-a0a8-eec5c978350a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4487/4487 [00:28<00:00, 159.18it/s]\n"
     ]
    }
   ],
   "source": [
    "r_precision_score = {}\n",
    "\n",
    "pbar = tqdm(total=unique_vendors.shape[0])\n",
    "# Iterating through all unique vendors in the test dataset\n",
    "for vendor_id in unique_vendors:\n",
    "    vendor_id = int(vendor_id)\n",
    "    \n",
    "    # Collecting one vendor at a time from the test dataset\n",
    "    test_adsidx = [i for i, x in enumerate(test_labels) if x == vendor_id]\n",
    "    test_vendor_embeddings, test_vendor_labels = ([] for i in range(2))\n",
    "    for _, ad_index in enumerate(test_adsidx):\n",
    "        test_vendor_embeddings.append(test_embeddings[ad_index])\n",
    "        test_vendor_labels.append(vendor_id)\n",
    "    \n",
    "    test_vendor_embeddings = torch.stack(test_vendor_embeddings)\n",
    "    test_vendor_labels = torch.tensor(test_vendor_labels)\n",
    "\n",
    "    # Performing K-Clustering for X relevant ads\n",
    "    D, I = gpu_index_flat.search(test_vendor_embeddings, vendor_dict[vendor_id])\n",
    "    \n",
    "    true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "    for index, rank_indices in enumerate(I):\n",
    "        temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "        label = test_vendor_labels[index]\n",
    "        \n",
    "        predicted_label_list.append(np.array(rank_indices))\n",
    "        true_label_list.append(np.where(train_labels == int(label))[0])\n",
    "    \n",
    "    # print(predicted_label_list)\n",
    "    # print(true_label_list)\n",
    "    r_precision_score[vendor_id] = np.mean(recall_at_k(true_label_list, predicted_label_list, vendor_dict[vendor_id]))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8710f71-b294-4302-b4b2-60b9ae34ca17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_rprecision_results_for_models(model=\"style\", model_type=\"trained\"):\n",
    "    if model_type == \"trained\":\n",
    "        train_embedding_filename = \"trained_traindata_\" + model + \"_mean.pt\"\n",
    "        train_label_filename = \"trained_trainlabels_\" + model + \"_mean.pt\"\n",
    "\n",
    "        test_embedding_filename = \"trained_testdata_\" + model + \"_mean.pt\"\n",
    "        test_label_filename = \"trained_testlabels_\" + model + \"_mean.pt\"\n",
    "    else:\n",
    "        train_embedding_filename = \"untrained_\" + model + \"data_train.pt\"\n",
    "        train_label_filename = \"untrained_\" + model + \"labels_train.pt\"\n",
    "\n",
    "        test_embedding_filename = \"untrained_\" + model + \"data_test.pt\"\n",
    "        test_label_filename = \"untrained_\" + model + \"labels_test.pt\"\n",
    "\n",
    "    train_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_embedding_filename), map_location=torch.device('cpu'))\n",
    "    train_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", train_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "    \n",
    "    test_embeddings = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_embedding_filename), map_location=torch.device('cpu'))\n",
    "    test_labels = torch.load(os.path.join(os.getcwd(), \"../pickled/embeddings/\", test_label_filename), map_location=torch.device('cpu')).detach().numpy()\n",
    "    \n",
    "    dim = train_embeddings.shape[1]\n",
    "    nb = train_embeddings.shape[0]\n",
    "    nq = train_embeddings.shape[0]\n",
    "\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    # make it a flat GPU index\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings) # add vectors to the index\n",
    "    \n",
    "    # The highest number of instances a vendor has in the training dataset is 1400\n",
    "    K = 1500\n",
    "    \n",
    "    vendor_dict = {}\n",
    "    unique_vendors = torch.unique(torch.tensor(test_labels))\n",
    "\n",
    "    pbar = tqdm(total=unique_vendors.shape[0])\n",
    "    for vendor_id in unique_vendors:\n",
    "        vendor_id = int(vendor_id)\n",
    "        # train_dataset\n",
    "        train_adsidx = [i for i, x in enumerate(train_labels) if x == vendor_id]\n",
    "        vendor_dict[vendor_id] = len(train_adsidx)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    \n",
    "    r_precision_score = {}\n",
    "\n",
    "    pbar = tqdm(total=unique_vendors.shape[0])\n",
    "    # Iterating through all unique vendors in the test dataset\n",
    "    for vendor_id in unique_vendors:\n",
    "        vendor_id = int(vendor_id)\n",
    "\n",
    "        # Collecting one vendor at a time from the test dataset\n",
    "        test_adsidx = [i for i, x in enumerate(test_labels) if x == vendor_id]\n",
    "        test_vendor_embeddings, test_vendor_labels = ([] for i in range(2))\n",
    "        for _, ad_index in enumerate(test_adsidx):\n",
    "            test_vendor_embeddings.append(test_embeddings[ad_index])\n",
    "            test_vendor_labels.append(vendor_id)\n",
    "\n",
    "        if model_type == \"trained\":\n",
    "            test_vendor_embeddings = torch.stack(test_vendor_embeddings)\n",
    "            test_vendor_labels = torch.tensor(test_vendor_labels)\n",
    "        else:\n",
    "            test_vendor_embeddings = torch.tensor(test_vendor_embeddings)\n",
    "            test_vendor_labels = torch.tensor(test_vendor_labels)\n",
    "\n",
    "        # Performing K-Clustering for X relevant ads\n",
    "        D, I = gpu_index_flat.search(test_vendor_embeddings, vendor_dict[vendor_id])\n",
    "\n",
    "        true_label_list, predicted_label_list = ([] for i in range(2))\n",
    "        for index, rank_indices in enumerate(I):\n",
    "            temp_predicted_list, temp_actual_list = ([] for i in range(2))\n",
    "            label = test_vendor_labels[index]\n",
    "\n",
    "            predicted_label_list.append(np.array(rank_indices))\n",
    "            true_label_list.append(np.where(train_labels == int(label))[0])\n",
    "\n",
    "        # print(predicted_label_list)\n",
    "        # print(true_label_list)\n",
    "        r_precision_score[vendor_id] = np.mean(recall_at_k(true_label_list, predicted_label_list, vendor_dict[vendor_id]))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    \n",
    "    print(\"R precision mean:\", np.mean(list(r_precision_score.values())))\n",
    "    print(\"R precision std:\", np.std(list(r_precision_score.values())))\n",
    "\n",
    "    return r_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e74b2-5a4b-41a3-a939-29061073c36d",
   "metadata": {},
   "source": [
    "# Style Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e87282b-b76c-4c84-8628-ab414a35618d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4487/4487 [00:56<00:00, 79.16it/s] \n",
      "100%|██████████| 4487/4487 [00:22<00:00, 196.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.8601571023493308\n",
      "R precision std: 0.22739694373594802\n"
     ]
    }
   ],
   "source": [
    "r_precision = generate_rprecision_results_for_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ddb74c-79a9-49ef-bc57-2712f6778371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4487/4487 [00:51<00:00, 87.16it/s] \n",
      "  0%|          | 0/4487 [00:00<?, ?it/s]/tmp/ipykernel_5751/1600327799.py:63: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  test_vendor_embeddings = torch.tensor(test_vendor_embeddings)\n",
      "100%|██████████| 4487/4487 [00:21<00:00, 207.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.019967233403539328\n",
      "R precision std: 0.07883495708402365\n"
     ]
    }
   ],
   "source": [
    "r_precision = generate_rprecision_results_for_models(model_type=\"untrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa362b92-29e8-401f-a241-ebb53f4d0541",
   "metadata": {},
   "source": [
    "# Declutr models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67edcd9-9bbf-4b64-9a07-2ce54ea79ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4487/4487 [00:49<00:00, 90.88it/s] \n",
      "100%|██████████| 4487/4487 [00:23<00:00, 191.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.8852071534463589\n",
      "R precision std: 0.2086283578160882\n"
     ]
    }
   ],
   "source": [
    "r_precision = generate_rprecision_results_for_models(model=\"declutr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c450ca46-0945-4841-81f2-470e10a96954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4487/4487 [00:49<00:00, 89.89it/s] \n",
      "100%|██████████| 4487/4487 [00:24<00:00, 185.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.16419733860200036\n",
      "R precision std: 0.23623486751891842\n"
     ]
    }
   ],
   "source": [
    "r_precision = generate_rprecision_results_for_models(model=\"declutr\", model_type=\"untrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d1678-b0e7-49c3-982c-dadfd1717679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
